{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_core as tf\n",
    "import tensorflow_core.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://www.macs.hw.ac.uk/InteractionLab/E2E/#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = 'dataset/e2e/trainset.csv'\n",
    "raw_df = pd.read_csv(raw_data)[['ref']]\n",
    "raw_df.to_csv('dataset/e2e/trainset_prepared.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'The Vaults pub near Caf\\xc3\\xa9 Adriatic has a 5 star rating.  Prices start at \\xc2\\xa330.', shape=(), dtype=string)\n",
      "tf.Tensor(b'\"Close to Caf\\xc3\\xa9 Brazil, The Cambridge Blue pub serves delicious Tuscan Beef for the cheap price of \\xc2\\xa310.50. Delicious Pub food.\"', shape=(), dtype=string)\n",
      "tf.Tensor(b'The Eagle is a low rated coffee shop near Burger King and the riverside that is family friendly and is less than \\xc2\\xa320 for Japanese food.', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "data = 'dataset/e2e/trainset_prepared.csv'\n",
    "lines = tf.data.TextLineDataset(data)\n",
    "\n",
    "for line in lines.take(3):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sentences into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'The' b'Vaults' b'pub' b'near' b'Caf\\xc3\\xa9' b'Adriatic' b'has' b'a'\n",
      " b'5' b'star' b'rating.'], shape=(11,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'Prices' b'start' b'at' b'\\xc2\\xa330.' b'\"Close' b'to' b'Caf\\xc3\\xa9'\n",
      " b'Brazil,' b'The' b'Cambridge' b'Blue'], shape=(11,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'pub' b'serves' b'delicious' b'Tuscan' b'Beef' b'for' b'the' b'cheap'\n",
      " b'price' b'of' b'\\xc2\\xa310.50.'], shape=(11,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "words = lines.map(tf.strings.split)\n",
    "wordsets = words.unbatch().batch(11)\n",
    "\n",
    "for row in wordsets.take(3):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get last words from sentences as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_label(row):\n",
    "    example = tf.strings.reduce_join(row[:-1], separator=' ')\n",
    "    example = tf.expand_dims(example, axis=0)\n",
    "    label = row[-1]\n",
    "    return example, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wordsets.map(get_example_label)\n",
    "data = data.shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'coffee shop that has Italian food and high customer rating.'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(), dtype=string, numpy=b'It'>)\n",
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
      "array([b'less than \\xc2\\xa320 price range with a low customer Rating.'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(), dtype=string, numpy=b'It'>)\n",
      "(<tf.Tensor: shape=(1,), dtype=string, numpy=array([b'has a high customer rating, and has a price range'], dtype=object)>, <tf.Tensor: shape=(), dtype=string, numpy=b'between'>)\n"
     ]
    }
   ],
   "source": [
    "for row in data.take(3):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=vocab_size, output_sequence_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(lines.batch(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'the', b'is', b'a', b'food', b'in']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'1out5', b'19', b'130', b'110', b'0f']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(tf.keras.models.Model):\n",
    "    def __init__(self, max_features=5000, embedding_dim=100, rnn_units=32):\n",
    "        super().__init__()\n",
    "        self.max_features = max_features\n",
    "        \n",
    "        self.vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=self.max_features, output_sequence_length=10)\n",
    "        \n",
    "        self.encoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=self.max_features+1, output_dim=embedding_dim)\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(units=rnn_units)\n",
    "        \n",
    "        self.decoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=self.max_features+1, output_dim=embedding_dim)\n",
    "        \n",
    "        projection_layer = tf.keras.layers.Dense(\n",
    "            units=max_features)\n",
    "        sampler = tfa.seq2seq.Sampler()\n",
    "        \n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.lstm_layer, sampler=sampler, output_layer=projection_layer)\n",
    "        \n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        X, y = data[0], data[1]\n",
    "        x = self.vectorize_layer(x)\n",
    "        y = self.vectorize_layer(y)[:, 0:1]\n",
    "        y = tf.one_hot(y, depth=self.max_features)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = self.encoder_embedding(x)\n",
    "            encoder_outputs, state_h, state_c = self.lstm_layer(inputs)\n",
    "            \n",
    "            attention_output = self.attention(encoder_outputs, state_h)\n",
    "            attention_output = tf.expand_dims(attention_output, axis=1)\n",
    "            \n",
    "            targets = self.decoder_embedding(tf.zeros_like(y))\n",
    "            concat_outputs = tf.concat([targets, attention_output], axis=-1)\n",
    "            \n",
    "            outputs, _, _ = self.decoder(concat_outputs, initial_state=[state_h, state_c])\n",
    "            \n",
    "#             gradients = tape.gradient(loss, )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
